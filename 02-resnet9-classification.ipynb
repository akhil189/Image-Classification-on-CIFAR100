{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2957b44-edb5-4095-aff1-2066e4d6896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    " \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from resnet9 import ResNet9\n",
    "from pipeline_jovian import Pipeline_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191919d9-503c-4588-8f15-d977270a6863",
   "metadata": {},
   "source": [
    "#### Computing Mean and Std of CIFAR-100 Training Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "205c8aa4-99ad-42ed-b3c4-e373f7d859aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "tensor([0.5071, 0.4866, 0.4409]) tensor([0.2009, 0.1984, 0.2023])\n",
      "CPU times: user 24.6 s, sys: 11.8 s, total: 36.3 s\n",
      "Wall time: 31.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./data',\n",
    "                                              train=True,\n",
    "                                              download=True,\n",
    "                                              transform=transforms.ToTensor())\n",
    "# Loading all images without batches\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=None,\n",
    "                                           num_workers=2,\n",
    "                                           pin_memory=True,\n",
    "                                           shuffle=False)\n",
    "\n",
    "mean, std  = torch.Tensor([0,0,0]), torch.Tensor([0,0,0])\n",
    "\n",
    "for i, (image, labels) in enumerate(train_loader):\n",
    "    mean += image.mean([1,2])\n",
    "    std += image.std([1,2])\n",
    "\n",
    "stats = ((mean / len(train_dataset)).tolist(), (std / len(train_dataset)).tolist())\n",
    "\n",
    "print(mean / len(train_dataset), std / len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5be35422-831a-445f-84f8-06fb094a135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.RandomCrop(32, padding=4,padding_mode='reflect'), \n",
    "                                           transforms.RandomHorizontalFlip(), \n",
    "                                           transforms.ToTensor(), \n",
    "                                           transforms.Normalize(*stats,inplace=True)\n",
    "                                          ])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize(*stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1537c58e-8052-4cab-bda6-87d4b5db583b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: GPU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline_v3(model = ResNet9(in_channels=3,\n",
    "                                    num_classes=100),\n",
    "                    loss = 'cross_entropy_loss',\n",
    "                    optimizer = 'adam',\n",
    "                    learning_rate = 0.01,\n",
    "                    batch_size = 400,\n",
    "                    num_epochs=25,\n",
    "                    weight_decay = 1e-4,\n",
    "                    train_transform = train_transform,\n",
    "                    test_transform = test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e300befb-ccf9-4438-928c-e726cb023c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Train set size: 50000\n",
      "Val set size: 10000\n",
      "Test set size: 10000\n",
      "\n",
      "Applied Transformations and loaded data\n",
      "\n",
      "batch size: 400, # batches(steps per epoch): 125\n",
      "\n",
      "Training...\n",
      "\n",
      "Epoch 1/25\n",
      "----------\n",
      "train Loss: 3.6433 Acc: 0.1520\n",
      "val Loss: 3.3518 Acc: 0.2154\n",
      "\n",
      "Epoch 2/25\n",
      "----------\n",
      "train Loss: 2.7666 Acc: 0.2973\n",
      "val Loss: 2.8494 Acc: 0.3243\n",
      "\n",
      "Epoch 3/25\n",
      "----------\n",
      "train Loss: 2.4321 Acc: 0.3735\n",
      "val Loss: 2.9713 Acc: 0.3274\n",
      "\n",
      "Epoch 4/25\n",
      "----------\n",
      "train Loss: 2.0783 Acc: 0.4466\n",
      "val Loss: 2.6989 Acc: 0.3576\n",
      "\n",
      "Epoch 5/25\n",
      "----------\n",
      "train Loss: 1.8737 Acc: 0.4908\n",
      "val Loss: 2.1636 Acc: 0.4377\n",
      "\n",
      "Epoch 6/25\n",
      "----------\n",
      "train Loss: 1.8168 Acc: 0.5127\n",
      "val Loss: 2.5080 Acc: 0.4055\n",
      "\n",
      "Epoch 7/25\n",
      "----------\n",
      "train Loss: 1.6842 Acc: 0.5438\n",
      "val Loss: 2.3877 Acc: 0.4437\n",
      "\n",
      "Epoch 8/25\n",
      "----------\n",
      "train Loss: 1.4631 Acc: 0.5905\n",
      "val Loss: 1.8591 Acc: 0.4991\n",
      "\n",
      "Epoch 9/25\n",
      "----------\n",
      "train Loss: 1.3749 Acc: 0.6097\n",
      "val Loss: 1.8998 Acc: 0.5072\n",
      "\n",
      "Epoch 10/25\n",
      "----------\n",
      "train Loss: 1.3359 Acc: 0.6216\n",
      "val Loss: 1.6332 Acc: 0.5500\n",
      "\n",
      "Epoch 11/25\n",
      "----------\n",
      "train Loss: 1.2664 Acc: 0.6377\n",
      "val Loss: 1.5689 Acc: 0.5679\n",
      "\n",
      "Epoch 12/25\n",
      "----------\n",
      "train Loss: 1.2133 Acc: 0.6539\n",
      "val Loss: 1.7059 Acc: 0.5416\n",
      "\n",
      "Epoch 13/25\n",
      "----------\n",
      "train Loss: 1.1731 Acc: 0.6614\n",
      "val Loss: 1.9776 Acc: 0.4924\n",
      "\n",
      "Epoch 14/25\n",
      "----------\n",
      "train Loss: 1.1034 Acc: 0.6776\n",
      "val Loss: 1.5782 Acc: 0.5807\n",
      "\n",
      "Epoch 15/25\n",
      "----------\n",
      "train Loss: 1.0430 Acc: 0.6963\n",
      "val Loss: 1.5036 Acc: 0.5815\n",
      "\n",
      "Epoch 16/25\n",
      "----------\n",
      "train Loss: 0.9642 Acc: 0.7151\n",
      "val Loss: 1.3464 Acc: 0.6234\n",
      "\n",
      "Epoch 17/25\n",
      "----------\n",
      "train Loss: 0.8709 Acc: 0.7406\n",
      "val Loss: 1.3229 Acc: 0.6395\n",
      "\n",
      "Epoch 18/25\n",
      "----------\n",
      "train Loss: 0.7550 Acc: 0.7755\n",
      "val Loss: 1.2089 Acc: 0.6593\n",
      "\n",
      "Epoch 19/25\n",
      "----------\n",
      "train Loss: 0.6382 Acc: 0.8066\n",
      "val Loss: 1.3767 Acc: 0.6421\n",
      "\n",
      "Epoch 20/25\n",
      "----------\n",
      "train Loss: 0.5100 Acc: 0.8447\n",
      "val Loss: 1.1447 Acc: 0.6947\n",
      "\n",
      "Epoch 21/25\n",
      "----------\n",
      "train Loss: 0.3815 Acc: 0.8863\n",
      "val Loss: 1.0454 Acc: 0.7200\n",
      "\n",
      "Epoch 22/25\n",
      "----------\n",
      "train Loss: 0.2801 Acc: 0.9199\n",
      "val Loss: 0.9970 Acc: 0.7307\n",
      "\n",
      "Epoch 23/25\n",
      "----------\n",
      "train Loss: 0.1935 Acc: 0.9478\n",
      "val Loss: 0.9688 Acc: 0.7401\n",
      "\n",
      "Epoch 24/25\n",
      "----------\n",
      "train Loss: 0.1533 Acc: 0.9625\n",
      "val Loss: 0.9712 Acc: 0.7404\n",
      "\n",
      "Epoch 25/25\n",
      "----------\n",
      "train Loss: 0.1370 Acc: 0.9687\n",
      "val Loss: 0.9716 Acc: 0.7410\n",
      "\n",
      "Training complete in 2m 29s\n",
      "Best val Acc: 0.7410 at epoch:25\n",
      "\n",
      "Testing...\n",
      "\n",
      "Accuracy of the network: 74.1 %\n",
      "Accuracy of apple: 85.0 %\n",
      "Accuracy of aquarium_fish: 87.0 %\n",
      "Accuracy of baby: 63.0 %\n",
      "Accuracy of bear: 61.0 %\n",
      "Accuracy of beaver: 60.0 %\n",
      "Accuracy of bed: 71.0 %\n",
      "Accuracy of bee: 85.0 %\n",
      "Accuracy of beetle: 74.0 %\n",
      "Accuracy of bicycle: 83.0 %\n",
      "Accuracy of bottle: 82.0 %\n",
      "Accuracy of bowl: 61.0 %\n",
      "Accuracy of boy: 42.0 %\n",
      "Accuracy of bridge: 83.0 %\n",
      "Accuracy of bus: 69.0 %\n",
      "Accuracy of butterfly: 66.0 %\n",
      "Accuracy of camel: 75.0 %\n",
      "Accuracy of can: 73.0 %\n",
      "Accuracy of castle: 84.0 %\n",
      "Accuracy of caterpillar: 66.0 %\n",
      "Accuracy of cattle: 69.0 %\n",
      "Accuracy of chair: 83.0 %\n",
      "Accuracy of chimpanzee: 91.0 %\n",
      "Accuracy of clock: 72.0 %\n",
      "Accuracy of cloud: 84.0 %\n",
      "Accuracy of cockroach: 84.0 %\n",
      "Accuracy of couch: 64.0 %\n",
      "Accuracy of crab: 70.0 %\n",
      "Accuracy of crocodile: 61.0 %\n",
      "Accuracy of cup: 82.0 %\n",
      "Accuracy of dinosaur: 76.0 %\n",
      "Accuracy of dolphin: 67.0 %\n",
      "Accuracy of elephant: 66.0 %\n",
      "Accuracy of flatfish: 61.0 %\n",
      "Accuracy of forest: 68.0 %\n",
      "Accuracy of fox: 77.0 %\n",
      "Accuracy of girl: 58.0 %\n",
      "Accuracy of hamster: 83.0 %\n",
      "Accuracy of house: 75.0 %\n",
      "Accuracy of kangaroo: 64.0 %\n",
      "Accuracy of keyboard: 89.0 %\n",
      "Accuracy of lamp: 70.0 %\n",
      "Accuracy of lawn_mower: 84.0 %\n",
      "Accuracy of leopard: 78.0 %\n",
      "Accuracy of lion: 82.0 %\n",
      "Accuracy of lizard: 51.0 %\n",
      "Accuracy of lobster: 66.0 %\n",
      "Accuracy of man: 51.0 %\n",
      "Accuracy of maple_tree: 71.0 %\n",
      "Accuracy of motorcycle: 95.0 %\n",
      "Accuracy of mountain: 82.0 %\n",
      "Accuracy of mouse: 65.0 %\n",
      "Accuracy of mushroom: 76.0 %\n",
      "Accuracy of oak_tree: 65.0 %\n",
      "Accuracy of orange: 90.0 %\n",
      "Accuracy of orchid: 89.0 %\n",
      "Accuracy of otter: 53.0 %\n",
      "Accuracy of palm_tree: 87.0 %\n",
      "Accuracy of pear: 81.0 %\n",
      "Accuracy of pickup_truck: 87.0 %\n",
      "Accuracy of pine_tree: 72.0 %\n",
      "Accuracy of plain: 86.0 %\n",
      "Accuracy of plate: 74.0 %\n",
      "Accuracy of poppy: 80.0 %\n",
      "Accuracy of porcupine: 68.0 %\n",
      "Accuracy of possum: 59.0 %\n",
      "Accuracy of rabbit: 63.0 %\n",
      "Accuracy of raccoon: 88.0 %\n",
      "Accuracy of ray: 63.0 %\n",
      "Accuracy of road: 94.0 %\n",
      "Accuracy of rocket: 79.0 %\n",
      "Accuracy of rose: 77.0 %\n",
      "Accuracy of sea: 89.0 %\n",
      "Accuracy of seal: 47.0 %\n",
      "Accuracy of shark: 56.0 %\n",
      "Accuracy of shrew: 51.0 %\n",
      "Accuracy of skunk: 91.0 %\n",
      "Accuracy of skyscraper: 89.0 %\n",
      "Accuracy of snail: 72.0 %\n",
      "Accuracy of snake: 69.0 %\n",
      "Accuracy of spider: 78.0 %\n",
      "Accuracy of squirrel: 57.0 %\n",
      "Accuracy of streetcar: 79.0 %\n",
      "Accuracy of sunflower: 91.0 %\n",
      "Accuracy of sweet_pepper: 69.0 %\n",
      "Accuracy of table: 71.0 %\n",
      "Accuracy of tank: 85.0 %\n",
      "Accuracy of telephone: 76.0 %\n",
      "Accuracy of television: 90.0 %\n",
      "Accuracy of tiger: 79.0 %\n",
      "Accuracy of tractor: 93.0 %\n",
      "Accuracy of train: 83.0 %\n",
      "Accuracy of trout: 84.0 %\n",
      "Accuracy of tulip: 70.0 %\n",
      "Accuracy of turtle: 60.0 %\n",
      "Accuracy of wardrobe: 91.0 %\n",
      "Accuracy of whale: 69.0 %\n",
      "Accuracy of willow_tree: 66.0 %\n",
      "Accuracy of wolf: 85.0 %\n",
      "Accuracy of woman: 56.0 %\n",
      "Accuracy of worm: 74.0 %\n",
      "CPU times: user 1min 32s, sys: 1min 6s, total: 2min 38s\n",
      "Wall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.runModel(grad_clip=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
